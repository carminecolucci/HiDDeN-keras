# -*- coding: utf-8 -*-
"""NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Du-O9dv8h_dOTM0KxadZQfed93Ucc6E5

## Import
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
from tensorflow.keras.backend import sqrt, sum, square
from tensorflow.keras import backend as K
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Conv2D, Flatten, Input, GlobalAveragePooling2D
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import string
import random


print(tf.__version__)

"""## Const"""

BATCH_SIZE = 128
KERNEL_SIZE = 3

"""## Utility"""

def generate_random_messages(N):
    messages = list()
    for _ in range(N):
        s = []
        text = "Hello, World!"
        binary_message = string_to_binary(text)
        for c in binary_message:
            s.append(float(c))
        s = np.asarray(s)
        messages.append(s)
    return np.asarray(messages)

def euclidean_distance_loss(y_true, y_pred):
    return sqrt(sum(square(y_pred - y_true), axis=-1))


def encoder_loss(y_true, y_pred):
    return euclidean_distance_loss(y_true, y_pred)

def decoder_loss(y_true, y_pred):
    return euclidean_distance_loss(y_true, y_pred)

def string_to_binary(string):
    # UTF-8 Encoding
    return ''.join(format(ord(x), 'b') for x in string)


#Encoder

def build_encoder(input_images, input_messages, encoder_filters, N):
    x = input_images
    _, H, W, C = input_images.shape

    # 4 ConvBnReLU
    for filters in encoder_filters:
        x = Conv2D(filters=filters,
                   kernel_size=KERNEL_SIZE,
                   strides=1,
                   padding='same')(x)
        x = BatchNormalization(axis=1)(x)
        x = Activation("relu")(x)

    # Phase 2
    """
       Here I'm concateneting msg, original image and conv_image
       from the previous layer.
       At the end of the for x_batch will contain all the images concatened.
    """

    for i in range(N):
        if i % 300 == 0:
            print(i)
        expanded_message = tf.expand_dims(input_messages[i], axis=0)
        b = tf.constant([H, W, 1], tf.int32)
        expanded_message = tf.convert_to_tensor(
            expanded_message, dtype=tf.float32)
        expanded_message = tf.tile(expanded_message, b)
        x2 = tf.concat([expanded_message, x[i], input_images[i]], -1)
        if i == 0:
            x_batch = x2
        else:
            x_batch = tf.concat([x_batch, x2], 0)

    # Phase 3
    # ConvBNReLU 5
    encoded_images = Conv2D(64,
                            kernel_size=KERNEL_SIZE,
                            strides=1,
                            padding='same')(x)
    encoded_images = BatchNormalization(axis=1)(encoded_images)
    encoded_images = Activation("relu")(encoded_images)

    # Final Convolutonial Layer, no padding
    encoded_images = Conv2D(C, 1, padding='same',
                            strides=1)(encoded_images)

    return encoded_images

#decoder

def build_decoder(encoded_images, decoder_filters, L):
    # 7 ConvBnReLU
    x = encoded_images
    for filters in decoder_filters:
        x = Conv2D(filters=filters,
                   kernel_size=KERNEL_SIZE,
                   strides=1,
                   padding='same')(x)
        x = BatchNormalization(axis=1)(x)
        x = Activation("relu")(x)

    # Last ConvBNReLU with L filters
    x = Conv2D(filters=L,
               kernel_size=KERNEL_SIZE,
               padding='same')(x)
    x = BatchNormalization(axis=1)(x)
    x = Activation("relu")(x)

    x = GlobalAveragePooling2D()(x)
    outputs = Activation('sigmoid', name='decoder_output')(x)

    return outputs

#autoencoder

def build_autoencoder(input_images, input_messages, encoder_filters, decoder_filters, N, L):
    encoded_images = build_encoder(input_images, input_messages, encoder_filters, N)

    decoded_messages = build_decoder(encoded_images, decoder_filters, L)

    return encoded_images, decoded_messages

"""## Autoencoder"""

# MNIST dataset
(x_train, _), (x_test, _) = mnist.load_data()
x_train = x_train[:5000]
x_test = x_test[:5000]
image_size = x_train.shape[1]
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = np.reshape(x_train, [-1, image_size, image_size, 1])
x_test = np.reshape(x_test, [-1, image_size, image_size, 1])
N = len(x_train)

# Network parameters
input_shape = (image_size, image_size, 1)  # H*W*C

# Encoder/Decoder number of CNN layers and filters per layer
encoder_filters = [64, 64, 64, 64]
decoder_filters = [64, 64, 64, 64, 64, 64, 64]
messages = generate_random_messages(N)
L = messages.shape[1]
print(f'L is {L}')

#Prepare inputs
message_shape = (1, L)
input_images = Input(shape=input_shape, name='encoder_input')
input_messages = Input(shape=message_shape)

#build the model
encoder, decoder = build_autoencoder(input_images, input_messages, encoder_filters, decoder_filters, N, L )


autoencoder = Model([input_images, input_messages], [encoder, decoder], name='autoencoder')
autoencoder.summary()
autoencoder.compile(loss=['mse', 'mse'], loss_weights = [1.0, 0.5], optimizer='adam')

# Train the autoencoder
autoencoder.fit([x_train, messages],
        [x_train, messages],
        epochs=100,
        batch_size=BATCH_SIZE)

"""## Predictions"""

x_decoded = autoencoder.predict([x_train, messages])

print(x_decoded[0])